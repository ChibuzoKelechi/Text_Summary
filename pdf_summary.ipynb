{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "pdf_text = PdfReader('2023_Kaggle_AI_Report.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "AI Report 2023 31\n",
      "Section Overview by Rob Mulla \n",
      "Topic Summary \n",
      "This section explores some of the latest advancements \n",
      "in computer vision, particularly as it relates to the use \n",
      "of image and video data. While the field of computer \n",
      "vision dates back to the 1960s, its evolution has been \n",
      "especially exciting over the last few decades. \n",
      "Specifically, over the past two years, there have been \n",
      "significant advancements not only in traditional \n",
      "computer vision tasks like classification and object \n",
      "detection, but also in emerging areas such as Vision \n",
      "Transformers (ViT) and few-shot learning. \n",
      "In addition to discussing model architectures, this \n",
      "section covers standard practices used in \n",
      "computer vision today like preprocessing and \n",
      "augmentation techniques. Additionally, this section \n",
      "explores the practical applications of these \n",
      "technologies across industries like healthcare (for \n",
      "medical imaging), agriculture (for crop monitoring), \n",
      "and the automotive sector (for self-driving cars). It \n",
      "also covers some of the limitations that computer \n",
      "vision still faces. \n",
      "Image / Video Data \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(pdf_text.pages))\n",
    "\n",
    "page = pdf_text.pages[30]\n",
    "page_text = page.extract_text()\n",
    "\n",
    "print(page_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kelechi/.pyenv/versions/3.10.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-02-11 16:24:56.348168: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-11 16:25:04.255221: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-11 16:25:04.256831: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-11 16:25:04.599811: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-11 16:25:05.354283: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-11 16:25:05.356012: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-11 16:25:40.301706: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "No model was supplied, defaulted to t5-small and revision d769bba (https://huggingface.co/t5-small).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 1.21k/1.21k [00:00<00:00, 1.55MB/s]\n",
      "model.safetensors: 100%|██████████| 242M/242M [02:18<00:00, 1.75MB/s] \n",
      "2024-02-11 16:28:32.806751: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 65798144 exceeds 10% of free system memory.\n",
      "2024-02-11 16:28:33.138903: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 65798144 exceeds 10% of free system memory.\n",
      "2024-02-11 16:28:33.496240: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 65798144 exceeds 10% of free system memory.\n",
      "2024-02-11 16:28:35.943036: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 65798144 exceeds 10% of free system memory.\n",
      "2024-02-11 16:28:37.202312: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 65798144 exceeds 10% of free system memory.\n",
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "tokenizer_config.json: 100%|██████████| 2.32k/2.32k [00:00<00:00, 1.16MB/s]\n",
      "spiece.model: 100%|██████████| 792k/792k [00:02<00:00, 346kB/s]\n",
      "tokenizer.json: 100%|██████████| 1.39M/1.39M [00:00<00:00, 2.35MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(task=\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-11 16:30:25.272076: I external/local_xla/xla/service/service.cc:168] XLA service 0x15406a50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-11 16:30:25.272142: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-02-11 16:30:25.511946: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1707665425.679737   18484 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-02-11 16:30:25.683257: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the field of computer vision dates back to the 1960s, but its evolution has been especially exciting over the last few decades . over the past two years, there have been significant advancements in traditional computer vision tasks like classification and object detection, but also in emerging areas such as vision Transformers (ViT)'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(page_text) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
